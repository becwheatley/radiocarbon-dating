---
title: "Sampling bias in radiocarbon dating project: broad approach 2 using the AustArch database"
author: "Rebecca Wheatley"
date: "7 May 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Set up

Load required packages:
```{r, message = FALSE}
library(ggformula)
library(plyr)
library(tidyverse)
library(data.table)
library(rcarbon)
library(parallel)
```

Specify path for source functions:
```{r, message = FALSE, echo = TRUE}
source("C:/Users/Bec/Work/Projects/Radiocarbon dating/GitHub/Analysis/broad_approach_2-source.R")
```

Load the AustArch data and make sure relevant columns read in correctly:
```{r, message = FALSE}
AustArch <- read.csv("C:/Users/Bec/Work/Projects/Radiocarbon dating/GitHub/Data/Austarch_1-3_and_IDASQ_28Nov13-1.csv")
AustArch$AGE_NORM     <- as.numeric(AustArch$AGE_NORM)
AustArch$ERROR        <- as.numeric(AustArch$ERROR)
AustArch$LATITUDE     <- as.numeric(AustArch$LATITUDE)
AustArch$LONGITUDE    <- as.numeric(AustArch$LONGITUDE)
AustArch$IBRA_REGION  <- as.factor(AustArch$IBRA_REGION)
AustArch$SITE         <- as.factor(AustArch$SITE)
```

Get rid of:  
* "unusable" samples 
* samples missing an age and/or error estimate  
* samples generated using any method that is not radiocarbon dating (this should be anything < 400 years BP for marine samples, and < 200 years for terrestrial samples)  
* samples that fall outside of the calibration age range
* samples that fall outside of the age range we are interested in (in this case, we only want Holocene dates)
```{r, message = FALSE, results = 'hide'}
data <- AustArch %>%
  dplyr::filter(Data.pertinent.for.time.series.analysis.or.calibration != "Unusuable") %>%
  dplyr::filter(AGE_NORM != "NA") %>%
  dplyr::filter(ERROR != "NA") %>%
  dplyr::filter(METHOD == "Radiocarbon") %>%
  dplyr::filter((AGE_NORM >= 400 & Data.pertinent.for.time.series.analysis.or.calibration == "Marine") 
                | (AGE_NORM >= 200 & Data.pertinent.for.time.series.analysis.or.calibration == "Terrestrial")) %>%
  subset(AGE_NORM <= 12000)
```

Create a new column that records the number of dated samples available for that site: NO_DATES_PER_SITE
```{r, message = FALSE}
data <- data %>%
  dplyr::arrange(SITE) %>%
  dplyr::group_by(SITE, .drop = TRUE) %>%
  dplyr::mutate(DATES_PER_SITE = length(AGE_NORM))
```

Create a new column that records a sample's position in the time series of the youngest dated sample at that site (1) to the oldest dated sample at that site (NO_DATES_PER_SITE): POSITION_IN_SERIES
```{r, message = FALSE}
data <- data %>%
  dplyr::arrange(SITE, AGE_NORM)
position <- vector(length = nrow(data))
for (i in 1:nrow(data)) {
  ## if we're not in row 1
  if (i > 1)
  {
    ## if the site in this row is the same as the site in the previous row
    if (data$SITE[i] == data$SITE[i-1]) { 
      position[i] <- position[i-1] + 1 ##
      ## if the site in this row is NOT the same as the site in the previous row
    } else {
      position[i] <- 1
    }
  } else { position[i] <- 1}
}
data$POSITION_IN_SERIES <- position
```

Create a new data set that contains only sites which have at least 5 samples. This will be our "baseline" data set, which we assume contains relatively little by way of sampling bias. We can then compare the results of common analysis methods (summed probability distributions, frequency distributions) using the baseline data set to those using various subsets of the baseline data which introduce known sampling biases.
```{r, message = FALSE}
baseline.data <- data %>% 
  subset(DATES_PER_SITE >= 5)
glimpse(data)
```

Create a new data set that contains only sites which have 1 sample. This will be our "singleton" data set, which we can add back in to the baseline data and compare the results of common analysis methods (summed probability distributions, frequency distributions).
```{r, message = FALSE}
singleton.data <- data %>% 
  subset(DATES_PER_SITE == 1)
```

Create a new data set that contains only sites which have 2 samples. This will be our "bracketed" data set, which we can add back in to the baseline data and compare the results of common analysis methods (summed probability distributions, frequency distributions).
```{r, message = FALSE}
bracketed.data <- data %>% 
  subset(DATES_PER_SITE == 2)
```

Create combined data sets:
```{r, message = FALSE}
baseline.plus.s   <- rbind(baseline.data, singleton.data)
baseline.plus.b  <- rbind(baseline.data, bracketed.data)
baseline.plus.s.b <- rbind(baseline.plus.s, bracketed.data)
```

## Generate and calibrate the baseline data, and the baseline data with the singleton and bracketed data addedo, t explore the effect of different sampling biases

Calibrate the baseline and other sample data (using the `'rcarbon` package):
```{r, message = FALSE, results = 'hide', progress_bar = FALSE}
normalised      = TRUE ## are calibration curves (and, later, SPDs) normalised?
cl              = detectCores()
ncores          = cl   ## the number of threads to use when calibrating the radiocarbon dates

# Baseline data
baseline.T  <- baseline.data %>% subset(Data.pertinent.for.time.series.analysis.or.calibration == "Terrestrial")
baseline.M  <- baseline.data %>% subset(Data.pertinent.for.time.series.analysis.or.calibration == "Marine")
cal.baseline.T    <- rcarbon::calibrate(x = baseline.T$AGE_NORM,
                                        errors = baseline.T$ERROR,
                                        ids = baseline.T$ADSID,
                                        calCurves = 'shcal20',
                                        normalised = normalised,
                                        ncores = ncores)
cal.baseline.M    <- rcarbon::calibrate(x = baseline.M$AGE_NORM,
                                        errors = baseline.M$ERROR,
                                        ids = baseline.M$ADSID,
                                        calCurves = 'marine20',
                                        normalised = normalised,
                                        ncores = ncores)
cal.baseline.data <- combine(cal.baseline.T, cal.baseline.M)


# Baseline + singleton
baseline.plus.s.T     <- baseline.plus.s %>% subset(Data.pertinent.for.time.series.analysis.or.calibration == "Terrestrial")
baseline.plus.s.M     <- baseline.plus.s %>% subset(Data.pertinent.for.time.series.analysis.or.calibration == "Marine")
cal.baseline.plus.s.T <- rcarbon::calibrate(x = baseline.plus.s.T$AGE_NORM,
                                            errors = baseline.plus.s.T$ERROR,
                                            ids = baseline.plus.s.T$ADSID,
                                            calCurves = 'shcal20',
                                            normalised = normalised,
                                            ncores = ncores)
cal.baseline.plus.s.M <- rcarbon::calibrate(x = baseline.plus.s.M$AGE_NORM,
                                           errors = baseline.plus.s.M$ERROR,
                                           ids = baseline.plus.s.M$ADSID,
                                           calCurves = 'marine20',
                                           normalised = normalised,
                                           ncores = ncores)
cal.baseline.plus.s <- combine(cal.baseline.plus.s.T, cal.baseline.plus.s.M)

# Baseline + bracketed
baseline.plus.b.T     <- baseline.plus.b %>% subset(Data.pertinent.for.time.series.analysis.or.calibration == "Terrestrial")
baseline.plus.b.M     <- baseline.plus.b %>% subset(Data.pertinent.for.time.series.analysis.or.calibration == "Marine")
cal.baseline.plus.b.T <- rcarbon::calibrate(x = baseline.plus.b.T$AGE_NORM,
                                            errors = baseline.plus.b.T$ERROR,
                                            ids = baseline.plus.b.T$ADSID,
                                            calCurves = 'shcal20',
                                            normalised = normalised,
                                            ncores = ncores)
cal.baseline.plus.b.M <- rcarbon::calibrate(x = baseline.plus.b.M$AGE_NORM,
                                           errors = baseline.plus.b.M$ERROR,
                                           ids = baseline.plus.b.M$ADSID,
                                           calCurves = 'marine20',
                                           normalised = normalised,
                                           ncores = ncores)
cal.baseline.plus.b <- combine(cal.baseline.plus.b.T, cal.baseline.plus.b.M)

# Baseline + singleton + bracketed
baseline.plus.s.b.T     <- baseline.plus.s.b %>% subset(Data.pertinent.for.time.series.analysis.or.calibration == "Terrestrial")
baseline.plus.s.b.M     <- baseline.plus.s.b %>% subset(Data.pertinent.for.time.series.analysis.or.calibration == "Marine")
cal.baseline.plus.s.b.T <- rcarbon::calibrate(x = baseline.plus.s.b.T$AGE_NORM,
                                            errors = baseline.plus.s.b.T$ERROR,
                                            ids = baseline.plus.s.b.T$ADSID,
                                            calCurves = 'shcal20',
                                            normalised = normalised,
                                            ncores = ncores)
cal.baseline.plus.s.b.M <- rcarbon::calibrate(x = baseline.plus.s.b.M$AGE_NORM,
                                           errors = baseline.plus.s.b.M$ERROR,
                                           ids = baseline.plus.s.b.M$ADSID,
                                           calCurves = 'marine20',
                                           normalised = normalised,
                                           ncores = ncores)
cal.baseline.plus.s.b <- combine(cal.baseline.plus.s.b.T, cal.baseline.plus.s.b.M)
```

## Generate and compare summed probability distributions (SPDs)

Calculate the summed probability distribution for each sample, and then compare to the baseline SPD:
```{r, message = FALSE,  results = 'hide', progress_bar = FALSE}
timeRange = c(12000, 0) ## time range we want our SPDs to cover
runm = 100              ## the running mean to use for the SPDs

spd.baseline <- rcarbon::spd(x = cal.baseline.data, 
                            timeRange = timeRange,
                            spdnormalised = normalised,
                            runm = runm)

spd.baseline.plus.s   <- rcarbon::spd(x = cal.baseline.plus.s, 
                                      timeRange = timeRange,
                                      spdnormalised = normalised,
                                      runm = runm)

spd.baseline.plus.b   <- rcarbon::spd(x = cal.baseline.plus.b, 
                                      timeRange = timeRange,
                                      spdnormalised = normalised,
                                      runm = runm)

spd.baseline.plus.s.b <- rcarbon::spd(x = cal.baseline.plus.s.b, 
                                      timeRange = timeRange,
                                      spdnormalised = normalised,
                                      runm = runm)
```

Plot the resulting summed probability distributions:  
* dashed black line is the SPD for the baseline data set  
* solid teal line is the SPD for the baseline + singleton data
* solid orange line is the SPD for the baseline + bracketed data
* sp;od blue line is the SPD for the baseline + singleton + bracketed data
```{r, echo = FALSE, message = TRUE}
ggplot(NULL) +
  geom_line(aes(x = spd.baseline.plus.s$grid$calBP, y = spd.baseline.plus.s$grid$PrDens), lwd = 1, color = "#66C2A5") +
  geom_line(aes(x = spd.baseline.plus.b$grid$calBP, y = spd.baseline.plus.b$grid$PrDens), lwd = 1, color = "#FC8D62") +
  geom_line(aes(x = spd.baseline.plus.s.b$grid$calBP, y = spd.baseline.plus.s.b$grid$PrDens), lwd = 1, color = "#8DA0CB") +
  geom_line(aes(x = spd.baseline$grid$calBP, y = spd.baseline$grid$PrDens), lwd = 1, colour = "black", linetype = "dashed") +
  labs(x = "Years cal BP", y = "Probability") +
  ggtitle("Summed probability distributions") +
  scale_x_reverse(limits=timeRange) +
  theme_bw()

```

## Generate and compare frequency distributions of dates within time bins

Calculate the frequency distribution for each data set:
```{r, message = FALSE,  results = 'hide', progress_bar = FALSE}
taphCorrect = TRUE     ## whether to taphonomically correct the open sites - not currently as haven't specified whether sites are open
correctForSite = FALSE ## per bin: number of sites with at least one date in them, or number of dates within the bin total
binSize = 100          ## the size of the bins to use (years) - use a bin size that actually fits the timeRange specified

# Get median bin age for x axis (same for all)
median.bin.age   <- seq(timeRange[2] + binSize/2, timeRange[1] - binSize/2, by = binSize)

# Baseline data
fd.baseline <- generate_frequency_dist(data = baseline.data,
                                        calibrated_data = cal.baseline.data,
                                        timeRange = timeRange,
                                        taphCorrect = taphCorrect,
                                        correctForSite = correctForSite,
                                        binSize = binSize)

# Baseline + singleton
fd.baseline.plus.s  <- generate_frequency_dist(data = baseline.plus.s,
                                               calibrated_data = cal.baseline.plus.s,
                                               timeRange = timeRange,
                                               taphCorrect = taphCorrect,
                                               correctForSite = correctForSite,
                                               binSize = binSize)
# Baseline + bracketed
fd.baseline.plus.b   <- generate_frequency_dist(data = baseline.plus.b,
                                                calibrated_data = cal.baseline.plus.b,
                                                timeRange = timeRange,
                                                taphCorrect = taphCorrect,
                                                correctForSite = correctForSite,
                                                binSize = binSize)

# Baseline + singleton + bracketed
fd.baseline.plus.s.d  <- generate_frequency_dist(data = baseline.plus.s.b,
                                                 calibrated_data = cal.baseline.plus.s.b,
                                                 timeRange = timeRange,
                                                 taphCorrect = taphCorrect,
                                                 correctForSite = correctForSite,
                                                 binSize = binSize)
```

Plot the resulting frequency distributions:  
* dashed black line is the frequency distribution for the baseline data set  
* solid teal line is the frequency distribution for the baseline + singleton data
* solid orange line is the frequency distribution for the baseline + bracketed data
* sp;od blue line is the frequency distribution for the baseline + singleton + bracketed data 
```{r, echo = FALSE}
# Uniform
ggplot(NULL) +
  geom_spline(aes(x = median.bin.age, y = fd.baseline.plus.s), lwd = 1, colour = "#66C2A5", df = 40) +
  geom_spline(aes(x = median.bin.age, y = fd.baseline.plus.b), lwd = 1, colour = "#FC8D62", df = 40) +
  geom_spline(aes(x = median.bin.age, y = fd.baseline.plus.s.d), lwd = 1, colour = "#8DA0CB", df = 40) +
  geom_spline(aes(x = median.bin.age, y = fd.baseline), lwd = 1, colour = "black", linetype = "dashed", df = 40) +
  labs(x = "Years cal BP", y = "Standardised frequency (frequency/sum(frequency) for each sample)") +
  ggtitle("Frequency distribution of dates in 100 year bins") +
  scale_x_reverse(limits=timeRange) +
  theme_bw()
```

### Frequency distributions of sites with dates within time bins

Calculate the frequency distribution for each data set:
```{r, message = FALSE,  results = 'hide', progress_bar = FALSE}
taphCorrect = FALSE    ## whether to taphonomically correct the open sites - not currently as haven't specified whether sites are open
correctForSite = TRUE  ## per bin: number of sites with at least one date in them, or number of dates within the bin total
binSize = 100          ## the size of the bins to use (years) - use a bin size that actually fits the timeRange specified

# Get median bin age for x axis (same for all)
median.bin.age   <- seq(timeRange[2] + binSize/2, timeRange[1] - binSize/2, by = binSize)

# Baseline data
fd.baseline.site <- generate_frequency_dist(data = baseline.data,
                                            calibrated_data = cal.baseline.data,
                                            timeRange = timeRange,
                                            taphCorrect = taphCorrect,
                                            correctForSite = correctForSite,
                                            binSize = binSize)

# Baseline + singleton
fd.baseline.plus.s.site  <- generate_frequency_dist(data = baseline.plus.s,
                                                    calibrated_data = cal.baseline.plus.s,
                                                    timeRange = timeRange,
                                                    taphCorrect = taphCorrect,
                                                    correctForSite = correctForSite,
                                                    binSize = binSize)
# Baseline + bracketed
fd.baseline.plus.b.site   <- generate_frequency_dist(data = baseline.plus.b,
                                                     calibrated_data = cal.baseline.plus.b,
                                                     timeRange = timeRange,
                                                     taphCorrect = taphCorrect,
                                                     correctForSite = correctForSite,
                                                     binSize = binSize)

# Baseline + singleton + bracketed
fd.baseline.plus.s.d.site  <- generate_frequency_dist(data = baseline.plus.s.b,
                                                      calibrated_data = cal.baseline.plus.s.b,
                                                      timeRange = timeRange,
                                                      taphCorrect = taphCorrect,
                                                      correctForSite = correctForSite,
                                                      binSize = binSize)
```

Plot the resulting frequency distributions:  
* dashed black line is the frequency distribution for the baseline data set  
* solid teal line is the frequency distribution for the baseline + singleton data
* solid orange line is the frequency distribution for the baseline + bracketed data
* sp;od blue line is the frequency distribution for the baseline + singleton + bracketed data 
```{r, echo = FALSE}
# Uniform
ggplot(NULL) +
  geom_spline(aes(x = median.bin.age, y = fd.baseline.plus.s.site), lwd = 1, colour = "#66C2A5", df = 40) +
  geom_spline(aes(x = median.bin.age, y = fd.baseline.plus.b.site), lwd = 1, colour = "#FC8D62", df = 40) +
  geom_spline(aes(x = median.bin.age, y = fd.baseline.plus.s.d.site), lwd = 1, colour = "#8DA0CB", df = 40) +
  geom_spline(aes(x = median.bin.age, y = fd.baseline.site), lwd = 1, colour = "black", linetype = "dashed", df = 40) +
  labs(x = "Years cal BP", y = "Standardised frequency (frequency/sum(frequency) for each sample)") +
  ggtitle("Frequency distribution of sites with dates in 100 year bins") +
  scale_x_reverse(limits=timeRange) +
  theme_bw()
```